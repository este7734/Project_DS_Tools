{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Die_Zeit_A2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/este7734/Project_DS_Tools/blob/master/Die_Zeit_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9EJGLekhe5n",
        "colab_type": "text"
      },
      "source": [
        "# Data Science Tools and Techniques\n",
        "\n",
        "# Web Scraping Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAasqXPAhe5s",
        "colab_type": "text"
      },
      "source": [
        "Beautiful Soup documentation: https://www.crummy.com/software/BeautifulSoup/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QftlYRQl-M2",
        "colab_type": "text"
      },
      "source": [
        "# <i>Die Zeit</i>\n",
        "\n",
        "---\n",
        "\n",
        "<div id=\"siteSub\" class=\"noprint\">From Wikipedia, the free encyclopedia</div>\n",
        "\n",
        "<p><i><b>Die Zeit</b></i> (<small>German pronunciation: </small><span title=\"Representation in the International Phonetic Alphabet (IPA)\" class=\"IPA\"><a href=\"/wiki/Help:IPA/Standard_German\" title=\"Help:IPA/Standard German\">[diː ˈtsaɪt]</a></span>, literally \"The Time\") is a German national <a href=\"/wiki/Weekly_newspaper\" title=\"Weekly newspaper\">weekly newspaper</a> published in <a href=\"/wiki/Hamburg\" title=\"Hamburg\">Hamburg</a> in <a href=\"/wiki/Germany\" title=\"Germany\">Germany</a>.<sup id=\"cite_ref-2\" class=\"reference\"><a href=\"#cite_note-2\">[2]</a></sup><sup id=\"cite_ref-3\" class=\"reference\"><a href=\"#cite_note-3\">[3]</a></sup> The newspaper is generally considered to be among the German <a href=\"/wiki/Newspapers_of_record\" class=\"mw-redirect\" title=\"Newspapers of record\">newspapers of record</a> and is known for its long and extensive articles.<sup id=\"cite_ref-4\" class=\"reference\"><a href=\"#cite_note-4\">[4]</a></sup>\n",
        "</p>\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R98YniHDK6Nq",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MgjXo4The5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFwkJ6Ihe52",
        "colab_type": "text"
      },
      "source": [
        "Create a Beautiful Soup object from an HTML sources:\n",
        "\n",
        "Use the following link to find an English version of Die Zeit article:\n",
        "https://www.zeit.de/english/index\n",
        "\n",
        "---\n",
        "For English articles:\n",
        "\n",
        "1. Stay on this page and load more articles by scrolling to bottom and click: **NÄCHSTE SEITE** (Next Site)\n",
        "5. Copy the weblink and add below as new URL variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p-WjahKhe53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get HTML page \n",
        "\n",
        "url1 = 'https://www.zeit.de/wirtschaft/2019-11/extinction-rebellion-co-founder-roger-hallam-holocaust'\n",
        "url2 = 'https://www.zeit.de/politik/ausland/2020-01/gabriel-zucman-donald-trump-plutocracy-usa'\n",
        "url3 = 'https://www.zeit.de/politik/2019-12/nato-trust-donald-trump-germany-security-policy'\n",
        "\n",
        "# A German and Czech talk about Europe as part of The Europe Talks \n",
        "url4_1 = 'https://www.zeit.de/gesellschaft/2019-05/tschechien-diskussion-teilnehmer-eu-europe-talks-english'\n",
        "url4_2 = 'https://www.zeit.de/gesellschaft/2019-05/tschechien-diskussion-teilnehmer-eu-europe-talks-english/seite-2'\n",
        "url4_3 = 'https://www.zeit.de/gesellschaft/2019-05/tschechien-diskussion-teilnehmer-eu-europe-talks-english/seite-3'\n",
        "\n",
        "# Russian agitators on Twitter are fueling discord in the West\n",
        "url5_1 = 'https://www.zeit.de/digital/2019-05/russia-trolls-twitter-european-elections-data-manipulation-english'\n",
        "url5_2 = 'https://www.zeit.de/digital/2019-05/russia-trolls-twitter-european-elections-data-manipulation-english/seite-2'\n",
        "url5_3 = 'https://www.zeit.de/digital/2019-05/russia-trolls-twitter-european-elections-data-manipulation-english/seite-3'\n",
        "url5_4 = 'https://www.zeit.de/digital/2019-05/russia-trolls-twitter-european-elections-data-manipulation-english/seite-4'\n",
        "\n",
        "# How the world that sees Merkel\n",
        "url6_1 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china'\n",
        "url6_2 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-2'\n",
        "url6_3 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-3'\n",
        "url6_4 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-4'\n",
        "url6_5 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-5'\n",
        "url6_6 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-6'\n",
        "url6_7 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-7'\n",
        "url6_8 = 'https://www.zeit.de/politik/deutschland/2017-09/german-election-angela-merkel-usa-russia-turkey-china/seite-8'\n",
        "\n",
        "# Nigel Farage Connections to Russia and sonsequences of Brexit\n",
        "url7_1 = 'https://www.zeit.de/politik/ausland/2017-05/nigel-farage-brexit-ukip-russia-contacts'\n",
        "url7_2 = 'https://www.zeit.de/politik/ausland/2017-05/nigel-farage-brexit-ukip-russia-contacts/seite-2'\n",
        "url7_3 = 'https://www.zeit.de/politik/ausland/2017-05/nigel-farage-brexit-ukip-russia-contacts/seite-3'\n",
        "url7_4 = 'https://www.zeit.de/politik/ausland/2017-05/nigel-farage-brexit-ukip-russia-contacts/seite-4'\n",
        "\n",
        "# Merkel hacked by Fancy Bear (Russian Cyber)\n",
        "url8_1 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia'\n",
        "url8_2 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia/seite-2'\n",
        "url8_3 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia/seite-3'\n",
        "url8_4 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia/seite-4'\n",
        "url8_5 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia/seite-5'\n",
        "url8_6 = 'https://www.zeit.de/digital/2017-05/cyberattack-bundestag-angela-merkel-fancy-bear-hacker-russia/seite-6'\n",
        "\n",
        "# Russia and the West - the disparity between the two when the Berlin Wall came down\n",
        "url9_1 = 'https://www.zeit.de/politik/ausland/2018-06/russia-relation-west-dmitry-glukhovsky-english'\n",
        "url9_2 = 'https://www.zeit.de/politik/ausland/2018-06/russia-relation-west-dmitry-glukhovsky-english/seite-2'\n",
        "url9_3 = 'https://www.zeit.de/politik/ausland/2018-06/russia-relation-west-dmitry-glukhovsky-english/seite-3'\n",
        "\n",
        "# Putinism works through fear\n",
        "url0_1 = 'https://www.zeit.de/politik/ausland/2018-01/russland-putin-medien-zensur-praesidentschaftswahl-soldatow-english'\n",
        "url0_2 = 'https://www.zeit.de/politik/ausland/2018-01/russland-putin-medien-zensur-praesidentschaftswahl-soldatow-english/seite-2'\n",
        "url0_3 = 'https://www.zeit.de/politik/ausland/2018-01/russland-putin-medien-zensur-praesidentschaftswahl-soldatow-english/seite-3'\n",
        "url0_4 = 'https://www.zeit.de/politik/ausland/2018-01/russland-putin-medien-zensur-praesidentschaftswahl-soldatow-english/seite-4'\n",
        "\n",
        "\n",
        "# Change the varbialbe in the .get method to the page you want to scrape\n",
        "page = requests.get(url3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rt9wxbyhe58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get soup\n",
        "def get_soup(page):\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    return soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJyvLrx8he6C",
        "colab_type": "text"
      },
      "source": [
        "Create a Beautiful Soup object from the imported HTML document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwh7PydThe6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = get_soup(page)\n",
        "#soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPhTNJ_Dhe6K",
        "colab_type": "text"
      },
      "source": [
        "## Open the HTML document in a text viewer.  Before you pull tag content, understand the tag structure of the document.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_gJkTbrNtWG",
        "colab_type": "text"
      },
      "source": [
        "Pull title from article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzAuhb_sqces",
        "colab_type": "code",
        "outputId": "022e4676-7525-4746-ae10-d3b71af03e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "title = soup.find_all('header')[1].contents[1].text\n",
        "print('length of test list: ', len(title), '\\n')\n",
        "print('Title: ', title)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of test list:  34 \n",
            "\n",
            "Title:  \n",
            "\n",
            "Nato: No More Excuses, Berlin!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92tuW95dN6DS",
        "colab_type": "text"
      },
      "source": [
        "Extract all the hyperlinks in the article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI50LXd-he6T",
        "colab_type": "raw"
      },
      "source": [
        "Anchors are used in HTML documents for a lot of different things.  One of the primary uses of anchors is to embed hyperlinks.  In the 'a' tag, there is an attribute called 'href' that specifies the hyperlink reference.\n",
        "\n",
        "The above markup will display a hyperlink that points 'hyperlink text' the href value.\n",
        "\n",
        "Beautiful soup can be used to pull specific inforamation from HTML tags.  For example, if you want all hyperlink references from links, you could use the following:\n",
        "\n",
        "links = []\n",
        "for item in anchors:\n",
        "    link = item.get('href')\n",
        "    links.append(link)\n",
        "\n",
        "You've already generated a list of all anchors.  Now, iterate over that list and collect all hyperlinks in the document in the space below, and print the list of hyperlinks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEEcBUz0c6bA",
        "colab_type": "text"
      },
      "source": [
        "## Extract hyperlinks for project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ECyoIz2he6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "20755184-6d9c-4984-8393-9d48621683ee"
      },
      "source": [
        "# Extract all href tags\n",
        "links = soup.find_all('link')\n",
        "\n",
        "# Separate hyperlinks from href tags\n",
        "all_hyperlinks = []\n",
        "for item in links:\n",
        "    link = item.get('href')\n",
        "    all_hyperlinks.append(link)\n",
        "print(all_hyperlinks)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://www.zeit.de/amp/politik/2019-12/nato-trust-donald-trump-germany-security-policy', 'https://www.zeit.de/politik/2019-12/nato-trust-donald-trump-germany-security-policy', 'https://www.zeit.de/politik/2019-12/nato-trust-donald-trump-germany-security-policy/seite-2', '//scripts.zeit.de', '//img.zeit.de', '//static.zeit.de', '//de.ioam.de', '//script.ioam.de', '//www.googletagmanager.com', '//www.google-analytics.com', '//scripts.zeit.de', '//img.zeit.de', '//static.zeit.de', '//script.ioam.de', '//iqdigital.demdex.net', '//audev.zeit.de', '//dmp.theadex.com', '//cdn.mateti.net', '//dpm.demdex.net', '//ups.xplosion.de', 'https://www.zeit.de/favicon.ico', 'https://img.zeit.de/static/img/ZO-ipad-114x114.png', 'https://static.zeit.de/assets/3.526/../latest/fonts/tabletgothic/TabletGothic-Regular.woff2?v1', 'https://static.zeit.de/assets/3.526/../latest/fonts/tabletgothic/TabletGothic-Bold.woff2?v1', 'https://static.zeit.de/assets/3.526/../latest/fonts/franziska/FranziskaWebPro.woff', 'https://static.zeit.de/assets/3.526/css/web.core/normalize.css', 'https://static.zeit.de/assets/3.526/css/web.site/base/base.css', 'https://static.zeit.de/assets/3.526/css/web.site/base/sticky-mobile-nav.css', 'https://static.zeit.de/assets/3.526/css/web.site/content/content.css', 'https://static.zeit.de/assets/3.526/css/web.site/content/comments.css', 'https://static.zeit.de/assets/3.526/css/web.site/content/article.css', 'https://static.zeit.de/assets/3.526/css/web.site/content/gallery.css', 'https://static.zeit.de/assets/3.526/css/web.site/base/print.css', 'https://img.zeit.de/politik/deutschland/2019-12/nato/wide__1300x731', 'https://newsfeed.zeit.de/index', 'https://img.zeit.de/2019/51/printcover/original', 'https://img.zeit.de/politik/deutschland/2019-12/nato/wide__822x462', 'https://img.zeit.de/2019/51/keine-ausreden-mehr-berlin-bild-1/square__460x460']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGTAp3UPhe6g",
        "colab_type": "text"
      },
      "source": [
        "Extract all p tabs to pull the article body"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF4n7pnEhe6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d3a93d44-e904-4aaf-ba58-d89ad5bd0e56"
      },
      "source": [
        "article_body = soup.find_all('p')\n",
        "print('Article Length: {} lines \\n'.format(len(article_body)))\n",
        "# print(article_body)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article Length: 15 lines \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NenHzzz8MioL",
        "colab": {}
      },
      "source": [
        "# Paragragh parser in place \n",
        "\n",
        "value1 = 'article-page'\n",
        "#value2 = 'RichText RichText--iconLinks RichText--lastPmb0 RichText--lastInline lg:w-8/12 md:w-10/12 lg:mx-auto md:mx-auto lg:px-24 md:px-24 sm:px-16 clearfix break-words word-wrap'\n",
        "#value_list = [value1, value2]\n",
        "\n",
        "#article_body = soup.find_all('div',{'class': value_list})\n",
        "article_body = soup.find_all('div',{'class': value1})\n",
        "#print('Length of list: {} items \\n'. format(len(article_body)))\n",
        "\n",
        "# Generate list of paragraphs\n",
        "p = []\n",
        "for item in article_body:\n",
        "    par = item.find_all('p')\n",
        "    p.extend(par)\n",
        "print('Length of article: {} paragraphs \\n'. format(len(p)))\n",
        "\n",
        "# Print last 4 words of last sentende to compare with article\n",
        "\n",
        "start_p = str(p[0]).split()\n",
        "end_p = str(p[len(p) - 1]).split()\n",
        "\n",
        "print('These are the first words of your scrape: \\n {} \\n'.format(start_p[2:10]))\n",
        "\n",
        "print('These are the last 4 words of your scrape: \\n {}\\n \\\n",
        "Compare this with the end of your article to see if \\\n",
        "you scraped everything \\n'.format(end_p[-6:-1]))\n",
        "\n",
        "# Extract content from the html tags\n",
        "\n",
        "file1 = open(\"MyFile.txt\",\"w\") # Open a text file to write to\n",
        "\n",
        "for item in p:\n",
        "    print(item.text)\n",
        "\n",
        "    file1.write(item.text) # write each string to the file \n",
        "\n",
        "file1.close() # close the file\n",
        "\n",
        "# In Colab the file is automatically save where you pointed it.\n",
        "# If you didn't change directories, then it will be here: \\content\\\n",
        "# Make sure you download the file before you close this session because\n",
        "# it will be wiped out when you close the session\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpKJR-nwRDwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5p1N_4s3Rk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}